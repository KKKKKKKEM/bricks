# -*- coding: utf-8 -*-
# @Time    : 2025-12-12
# @Author  : Kem
# @Desc    : åª’ä½“æ–‡ä»¶ä¸‹è½½å™¨ - æ”¯æŒæ–­ç‚¹ç»­ä¼ ã€æµå¼ä¸‹è½½ã€è¿›åº¦æ˜¾ç¤º
import copy
import csv
import json
import os
import pathlib
import threading
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from typing import Any, Callable, Dict, List, Optional, Union

from bricks.utils import pandora

pandora.require("tqdm")

from loguru import logger  # noqa: E402
from tqdm import tqdm  # noqa: E402

from bricks.downloader import AbstractDownloader  # noqa: E402
from bricks.downloader.cffi import Downloader as CffiDownloader  # noqa: E402
from bricks.lib.request import Request  # noqa: E402


@dataclass
class DownloadTask:
    """ä¸‹è½½ä»»åŠ¡"""
    request: Request
    save_path: str
    filename: Optional[str] = None
    resume: bool = True  # æ˜¯å¦æ”¯æŒæ–­ç‚¹ç»­ä¼ 
    skip_existing: bool = True  # æ˜¯å¦è·³è¿‡å·²ä¸‹è½½
    progress_callback: Optional[Callable[[
        int, int, float], None]] = None  # è¿›åº¦å›è°ƒ

    def __post_init__(self):
        if not self.filename:
            self.filename = os.path.basename(
                self.request.real_url.split('?')[0]) or f"file_{int(time.time())}"

    @property
    def full_path(self) -> str:
        """å®Œæ•´æ–‡ä»¶è·¯å¾„"""
        return os.path.join(self.save_path, self.filename or "")

    @property
    def temp_path(self) -> str:
        """ä¸´æ—¶æ–‡ä»¶è·¯å¾„"""
        return f"{self.full_path}.part"

    @property
    def meta_path(self) -> str:
        """å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„"""
        return f"{self.full_path}.meta"


class DownloadMeta:
    """ä¸‹è½½å…ƒæ•°æ®ç®¡ç†"""

    def __init__(self, task: DownloadTask):
        self.task = task
        self.total_size: int = 0
        self.downloaded_size: int = 0
        self.support_range: bool = False
        self.etag: Optional[str] = None
        self.last_modified: Optional[str] = None

    def load(self) -> bool:
        """åŠ è½½å…ƒæ•°æ®"""
        if not os.path.exists(self.task.meta_path):
            return False

        try:
            with open(self.task.meta_path, 'r', encoding='utf-8') as f:
                data = json.load(f)

            self.total_size = data['total_size']
            self.downloaded_size = data['downloaded_size']
            self.support_range = data['support_range']
            self.etag = data.get('etag')
            self.last_modified = data.get('last_modified')

            return True
        except Exception as e:
            logger.warning(f"åŠ è½½å…ƒæ•°æ®å¤±è´¥: {e}")
            return False

    def save(self):
        """ä¿å­˜å…ƒæ•°æ®"""
        try:
            data = {
                'total_size': self.total_size,
                'downloaded_size': self.downloaded_size,
                'support_range': self.support_range,
                'etag': self.etag,
                'last_modified': self.last_modified,
            }

            with open(self.task.meta_path, 'w', encoding='utf-8') as f:
                json.dump(data, f)
        except Exception as e:
            logger.error(f"ä¿å­˜å…ƒæ•°æ®å¤±è´¥: {e}")

    def cleanup(self):
        """æ¸…ç†å…ƒæ•°æ®æ–‡ä»¶"""
        try:
            if os.path.exists(self.task.meta_path):
                os.remove(self.task.meta_path)
        except Exception as e:
            logger.warning(f"æ¸…ç†å…ƒæ•°æ®æ–‡ä»¶å¤±è´¥: {e}")


class MediaDownloader:
    """
    åª’ä½“æ–‡ä»¶ä¸‹è½½å™¨

    ç‰¹æ€§ï¼š
    - æ”¯æŒæ–­ç‚¹ç»­ä¼ 
    - æµå¼ä¸‹è½½ï¼Œå†…å­˜å ç”¨ä½
    - æ”¯æŒè¿›åº¦å›è°ƒ
    - è‡ªåŠ¨è·³è¿‡å·²ä¸‹è½½æ–‡ä»¶
    - é›†æˆç°æœ‰ä¸‹è½½å™¨ç‰¹æ€§

    ç¤ºä¾‹ï¼š
        downloader = MediaDownloader()

        # ç®€å•ä¸‹è½½
        request = Request(url="https://example.com/video.mp4")
        downloader.download(
            request=request,
            save_path="./downloads"
        )

        # å¸¦è¿›åº¦å›è°ƒ
        downloader.download(
            request=request,
            save_path="./downloads",
            progress_callback=lambda downloaded, total, speed:
                print(f"å·²ä¸‹è½½: {downloaded}/{total} é€Ÿåº¦: {speed:.2f}MB/s")
        )
    """

    def __init__(
        self,
        downloader: Optional[AbstractDownloader] = None,
        chunk_size: int = 8192,
        prepare_row: Optional[Callable[[
            Dict[str, Any]], Dict[str, Any]]] = None,
        prepare_url: Optional[Callable[[
            str, str, Dict[str, Any]], str]] = None,
        prepare_filename: Optional[Callable[[
            Optional[str], str, Dict[str, Any]], Optional[str]]] = None,
        prepare_headers: Optional[Callable[[
            Dict[str, str], str, str, Dict[str, Any]], Dict[str, str]]] = None,
        resolve_output_path: Optional[Callable[[
            pathlib.Path, str, str, Optional[str], Dict[str, Any]], pathlib.Path]] = None,
        on_result: Optional[Callable[[bool, str, str, pathlib.Path,
                                      Dict[str, Any], Optional[Exception]], None]] = None,
    ):
        """
        åˆå§‹åŒ–åª’ä½“ä¸‹è½½å™¨

        :param downloader: ä½¿ç”¨çš„ä¸‹è½½å™¨å®ä¾‹ï¼Œé»˜è®¤ä½¿ç”¨ CffiDownloader
        :param chunk_size: ä¸‹è½½æ—¶çš„å—å¤§å°ï¼Œé»˜è®¤ 8192 å­—èŠ‚
        :param prepare_row: è¡Œæ•°æ®é¢„å¤„ç†å›è°ƒ (row) -> row
        :param prepare_url: URL é¢„å¤„ç†å›è°ƒ (url, media_id, row) -> url
        :param prepare_filename: æ–‡ä»¶åé¢„å¤„ç†å›è°ƒ (filename, media_id, row) -> filename
        :param prepare_headers: è¯·æ±‚å¤´é¢„å¤„ç†å›è°ƒ (headers, url, media_id, row) -> headers
        :param resolve_output_path: è‡ªå®šä¹‰è¾“å‡ºè·¯å¾„å›è°ƒ (download_dir, url, media_id, filename, row) -> path
        :param on_result: ä¸‹è½½ç»“æœå›è°ƒ (success, url, media_id, path, row, error) -> None
        """
        self.downloader = downloader or CffiDownloader()
        self.chunk_size = chunk_size

        # Hook å›è°ƒå‡½æ•°
        self.prepare_row = prepare_row
        self.prepare_url = prepare_url
        self.prepare_filename = prepare_filename
        self.prepare_headers = prepare_headers
        self.resolve_output_path = resolve_output_path
        self.on_result = on_result

        # çº¿ç¨‹æœ¬åœ°å­˜å‚¨ï¼Œç”¨äºç®¡ç†æ¯ä¸ªçº¿ç¨‹çš„ tqdm è¿›åº¦æ¡ä½ç½®
        self._thread_local = threading.local()
        self._position_lock = threading.Lock()
        self._position_map: Dict[int, int] = {}
        self._next_position = 0

        # é…ç½® logger ä¸ tqdm å…¼å®¹
        logger.remove()
        logger.add(lambda msg: tqdm.write(msg, end=""), colorize=True)

    def _get_position(self) -> int:
        """è·å–å½“å‰çº¿ç¨‹çš„ tqdm è¿›åº¦æ¡ä½ç½®"""
        tid = threading.get_ident()
        with self._position_lock:
            pos = self._position_map.get(tid)
            if pos is None:
                pos = self._next_position
                self._next_position += 1
                self._position_map[tid] = pos
            return pos

    @staticmethod
    def _safe_rename_file(src: pathlib.Path, dst: pathlib.Path) -> bool:
        """å®‰å…¨åœ°é‡å‘½åæ–‡ä»¶ï¼ˆåŸå­æ“ä½œï¼‰

        Args:
            src: æºæ–‡ä»¶è·¯å¾„
            dst: ç›®æ ‡æ–‡ä»¶è·¯å¾„

        Returns:
            æ˜¯å¦æˆåŠŸé‡å‘½å
        """
        try:
            src.rename(dst)
            return True
        except (FileNotFoundError, OSError) as e:
            logger.warning(f"æ–‡ä»¶é‡å‘½åå¤±è´¥: {e}")
            return False

    def download(
        self,
        request: Request,
        save_path: str,
        filename: Optional[str] = None,
        resume: bool = True,
        skip_existing: bool = True,
        progress_callback: Optional[Callable[[int, int, float], None]] = None,
        show_progress: bool = True,
        media_id: Optional[str] = None,
        row_data: Optional[Dict[str, Any]] = None,
    ) -> bool:
        """
        ä¸‹è½½æ–‡ä»¶

        :param request: è¯·æ±‚å¯¹è±¡
        :param save_path: ä¿å­˜ç›®å½•
        :param filename: æ–‡ä»¶åï¼Œé»˜è®¤ä» URL è§£æ
        :param resume: æ˜¯å¦æ”¯æŒæ–­ç‚¹ç»­ä¼ 
        :param skip_existing: æ˜¯å¦è·³è¿‡å·²å­˜åœ¨çš„æ–‡ä»¶
        :param progress_callback: è¿›åº¦å›è°ƒå‡½æ•° (downloaded, total, speed)ï¼Œä¸º None æ—¶ä½¿ç”¨ tqdm è¿›åº¦æ¡
        :param show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡ï¼ˆä»…åœ¨ progress_callback ä¸º None æ—¶æœ‰æ•ˆï¼‰
        :param media_id: åª’ä½“IDï¼Œç”¨äº hook å›è°ƒ
        :param row_data: è¡Œæ•°æ®ï¼Œç”¨äº hook å›è°ƒ
        :return: æ˜¯å¦ä¸‹è½½æˆåŠŸ
        """
        row_data = row_data or {}
        media_id = media_id or ""
        url = request.real_url

        # åº”ç”¨ URL hook
        if self.prepare_url:
            try:
                url = self.prepare_url(url, media_id, row_data)
                request = copy.deepcopy(request)
                request.url = url
            except Exception as e:
                logger.error(f"prepare_url å¤±è´¥: {e}")
                if self.on_result:
                    self.on_result(False, url, media_id, pathlib.Path(
                        save_path) / (filename or ""), row_data, e)
                return False

        # åº”ç”¨æ–‡ä»¶å hook
        if self.prepare_filename:
            try:
                filename = self.prepare_filename(filename, media_id, row_data)
            except Exception as e:
                logger.error(f"prepare_filename å¤±è´¥: {e}")
                if self.on_result:
                    self.on_result(False, url, media_id, pathlib.Path(
                        save_path) / (filename or ""), row_data, e)
                return False

        # åº”ç”¨è‡ªå®šä¹‰è·¯å¾„ hook
        if self.resolve_output_path:
            try:
                full_path = self.resolve_output_path(pathlib.Path(
                    save_path), url, media_id, filename, row_data)
                save_path = str(full_path.parent)
                filename = full_path.name
            except Exception as e:
                logger.error(f"resolve_output_path å¤±è´¥: {e}")
                if self.on_result:
                    self.on_result(False, url, media_id, pathlib.Path(
                        save_path) / (filename or ""), row_data, e)
                return False

        # åº”ç”¨è¯·æ±‚å¤´ hook
        if self.prepare_headers:
            try:
                headers = dict(request.headers or {})
                headers = self.prepare_headers(
                    headers, url, media_id, row_data)
                request = copy.deepcopy(request)
                request.headers.update(headers)
            except Exception as e:
                logger.error(f"prepare_headers å¤±è´¥: {e}")
                if self.on_result:
                    self.on_result(False, url, media_id, pathlib.Path(
                        save_path) / (filename or ""), row_data, e)
                return False

        task = DownloadTask(
            save_path=save_path,
            filename=filename,
            resume=resume,
            skip_existing=skip_existing,
            progress_callback=progress_callback,
            request=request
        )

        # ä¿å­˜é¢å¤–ä¿¡æ¯åˆ°ä»»åŠ¡å¯¹è±¡
        task.__dict__['show_progress'] = show_progress
        task.__dict__['media_id'] = media_id
        task.__dict__['row_data'] = row_data

        result = self.download_task(task)

        # è°ƒç”¨ç»“æœå›è°ƒ
        if self.on_result:
            error = None if result else Exception("ä¸‹è½½å¤±è´¥")
            self.on_result(result, url, media_id, pathlib.Path(
                task.full_path), row_data, error)

        return result

    def download_task(self, task: DownloadTask) -> bool:
        """
        æ‰§è¡Œä¸‹è½½ä»»åŠ¡

        :param task: ä¸‹è½½ä»»åŠ¡
        :return: æ˜¯å¦ä¸‹è½½æˆåŠŸ
        """
        # åˆ›å»ºä¿å­˜ç›®å½•
        pathlib.Path(task.save_path).mkdir(parents=True, exist_ok=True)

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        if task.skip_existing and os.path.exists(task.full_path):
            logger.info(f"æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½: {task.full_path}")
            return True

        try:
            # è·å–æ–‡ä»¶ä¿¡æ¯
            meta = self._get_file_info(task)
            if meta is None:
                return False

            # ä½¿ç”¨å•çº¿ç¨‹æµå¼ä¸‹è½½
            return self._download_single(task, meta)

        except Exception as e:
            logger.error(f"ä¸‹è½½å¤±è´¥: {e}")
            return False

    def _get_file_info(self, task: DownloadTask) -> Optional[DownloadMeta]:
        """è·å–æ–‡ä»¶ä¿¡æ¯"""
        meta = DownloadMeta(task)

        # å°è¯•åŠ è½½å·²æœ‰çš„å…ƒæ•°æ®
        if task.resume and meta.load():
            logger.info(
                f"åŠ è½½æ–­ç‚¹ç»­ä¼ ä¿¡æ¯ï¼Œå·²ä¸‹è½½: {meta.downloaded_size}/{meta.total_size}")

            # éªŒè¯æ–‡ä»¶æ˜¯å¦æœ‰å˜åŒ–
            if self._verify_file_unchanged(task, meta):
                return meta
            else:
                logger.warning("è¿œç¨‹æ–‡ä»¶å·²æ›´æ”¹ï¼Œé‡æ–°ä¸‹è½½")
                meta.cleanup()

        # å‘é€ HEAD è¯·æ±‚è·å–æ–‡ä»¶ä¿¡æ¯
        try:
            # æ·±æ‹·è´ Request å¯¹è±¡é¿å…ä¿®æ”¹åŸå¯¹è±¡ï¼ˆåŒ…æ‹¬ headers ç­‰å¯å˜å¯¹è±¡ï¼‰
            request = copy.deepcopy(task.request)
            request.method = "HEAD"

            response = self.downloader.fetch(request)
            if response.status_code == 405:
                logger.warning("æœåŠ¡å™¨ä¸æ”¯æŒ HEAD è¯·æ±‚ï¼Œå°†ä½¿ç”¨æµå¼ä¸‹è½½")
                meta.total_size = 0
                meta.support_range = False
                return meta

            if response.status_code not in [200, 206]:
                logger.warning(f"HEAD è¯·æ±‚å¤±è´¥: {response.status_code}ï¼Œå°è¯•ç›´æ¥ä¸‹è½½")
                meta.total_size = 0
                meta.support_range = False
                return meta

            # è§£ææ–‡ä»¶å¤§å°
            content_length = response.headers.get('Content-Length')
            if not content_length:
                logger.warning("æ— æ³•è·å–æ–‡ä»¶å¤§å°ï¼Œå°†ä½¿ç”¨æµå¼ä¸‹è½½")
                meta.total_size = 0
            else:
                meta.total_size = int(content_length)

            # æ£€æŸ¥æ˜¯å¦æ”¯æŒ Range è¯·æ±‚
            accept_ranges = response.headers.get('Accept-Ranges', '').lower()
            meta.support_range = accept_ranges == 'bytes'

            # ä¿å­˜ ETag å’Œ Last-Modified ç”¨äºéªŒè¯
            meta.etag = response.headers.get('ETag')
            meta.last_modified = response.headers.get('Last-Modified')

            logger.info(
                f"æ–‡ä»¶å¤§å°: {meta.total_size} bytes, "
                f"æ”¯æŒæ–­ç‚¹ç»­ä¼ : {meta.support_range}"
            )

            return meta

        except Exception as e:
            logger.warning(f"HEAD è¯·æ±‚å¼‚å¸¸: {e}ï¼Œå°†ä½¿ç”¨æµå¼ä¸‹è½½")
            # å‘ç”Ÿå¼‚å¸¸æ—¶ä¹Ÿè¿”å› metaï¼Œä½¿ç”¨æµå¼ä¸‹è½½
            meta.total_size = 0
            meta.support_range = False
            return meta

    def _verify_file_unchanged(self, task: DownloadTask, meta: DownloadMeta) -> bool:
        """éªŒè¯è¿œç¨‹æ–‡ä»¶æ˜¯å¦æœªæ”¹å˜"""
        try:
            # æ·±æ‹·è´ Request å¯¹è±¡é¿å…ä¿®æ”¹åŸå¯¹è±¡ï¼ˆåŒ…æ‹¬ headers ç­‰å¯å˜å¯¹è±¡ï¼‰
            request = copy.deepcopy(task.request)
            request.method = "HEAD"

            response = self.downloader.fetch(request)

            # æ¯”è¾ƒ ETag
            if meta.etag and response.headers.get('ETag'):
                return meta.etag == response.headers.get('ETag')

            # æ¯”è¾ƒ Last-Modified
            if meta.last_modified and response.headers.get('Last-Modified'):
                return meta.last_modified == response.headers.get('Last-Modified')

            # æ¯”è¾ƒæ–‡ä»¶å¤§å°
            content_length = response.headers.get('Content-Length')
            if content_length:
                return meta.total_size == int(content_length)

            return False

        except Exception:
            return False

    @staticmethod
    def custom_bar_format(d):
        progress = f"{d['n_fmt']}/{d['total_fmt']}"
        return (
            f"{d['desc']:30} â”‚ {d['bar']:25} {d['percentage']:6.2f}% â”‚ "
            f"{progress:>12} â”‚ {d['rate_fmt']:>10} â”‚ {d['elapsed']:>5} â”‚ {d['remaining']:>5}"
        )

    def _download_single(self, task: DownloadTask, meta: DownloadMeta) -> bool:
        """å•çº¿ç¨‹ä¸‹è½½ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ å’Œæ™ºèƒ½é‡è¯•ï¼‰"""
        logger.info(f"å¼€å§‹ä¸‹è½½: {task.request.real_url}")

        # è·Ÿè¸ªæœåŠ¡å™¨æ˜¯å¦æ”¯æŒæ–­ç‚¹ç»­ä¼ 
        # None: æœªçŸ¥, True: æ”¯æŒ(è¿”å›206), False: ä¸æ”¯æŒ(è¿”å›200)
        supports_resume = None
        max_retries = 3

        for attempt in range(max_retries):
            try:
                # æ„å»ºè¯·æ±‚å¤´
                headers = dict(task.request.headers or {})

                # æ£€æŸ¥æ˜¯å¦æœ‰å·²ä¸‹è½½å†…å®¹
                downloaded_size = 0
                if os.path.exists(task.temp_path):
                    downloaded_size = os.path.getsize(task.temp_path)
                    if downloaded_size > 0 and meta.support_range:
                        headers['Range'] = f'bytes={downloaded_size}-'
                        logger.info(f"ä» {downloaded_size} å­—èŠ‚å¤„ç»§ç»­ä¸‹è½½")

                # æ·±æ‹·è´ Request å¯¹è±¡é¿å…ä¿®æ”¹åŸå¯¹è±¡
                request = copy.deepcopy(task.request)
                request.method = "GET"
                request.headers.update(headers)
                request.put_options("stream", True)
                request.put_options("chunk_size", self.chunk_size)

                response = self.downloader.fetch(request)

                # å¤„ç†ä¸æ”¯æŒæ–­ç‚¹ç»­ä¼ çš„æƒ…å†µï¼ˆæœåŠ¡å™¨è¿”å› 200 è€Œé 206ï¼‰
                if downloaded_size > 0 and response.status_code == 200:
                    logger.warning("æœåŠ¡å™¨ä¸æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œåˆ é™¤ä¸´æ—¶æ–‡ä»¶é‡æ–°ä¸‹è½½")
                    supports_resume = False
                    if os.path.exists(task.temp_path):
                        os.remove(task.temp_path)
                    downloaded_size = 0
                    headers.pop('Range', None)
                    continue  # é‡æ–°ä¸‹è½½

                # è®°å½•æœåŠ¡å™¨æ˜¯å¦æ”¯æŒæ–­ç‚¹ç»­ä¼ 
                if downloaded_size > 0 and response.status_code == 206:
                    supports_resume = True
                elif response.status_code == 200:
                    if supports_resume is None:
                        supports_resume = True  # ä¿å®ˆç­–ç•¥ï¼Œå‡è®¾æ”¯æŒ

                # å¤„ç† 429 é™æµ
                if response.status_code == 429:
                    retry_after = response.headers.get("Retry-After")
                    if retry_after and retry_after.isdigit():
                        wait_time = int(retry_after)
                    else:
                        wait_time = max(10, 2 ** (attempt + 3))

                    logger.warning(
                        f"é‡åˆ° 429 é™æµï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯• (å°è¯• {attempt + 1}/{max_retries})")
                    if attempt < max_retries - 1:
                        time.sleep(wait_time)
                        continue
                    else:
                        logger.error("è¯·æ±‚è¢«é™æµ (429)ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°")
                        return False

                if response.status_code not in [200, 206]:
                    logger.error(f"ä¸‹è½½å¤±è´¥: {response.status_code}")
                    if attempt < max_retries - 1:
                        time.sleep(2 ** attempt)
                        continue
                    return False

                # æ›´æ–°æ€»å¤§å°
                content_length = response.headers.get('Content-Length')
                if content_length:
                    total_size = int(content_length) + downloaded_size
                else:
                    total_size = 0

                meta.total_size = total_size
                meta.downloaded_size = downloaded_size

                # æµå¼å†™å…¥æ–‡ä»¶
                mode = 'ab' if downloaded_size > 0 else 'wb'

                # å‡†å¤‡æ–‡ä»¶åç”¨äºè¿›åº¦æ˜¾ç¤º
                file_name = os.path.basename(task.full_path)
                desc_width = 25
                resume_icon = "â¯ï¸ " if downloaded_size > 0 else "ğŸ“¥"
                icon_width = 3
                filename_width = desc_width - icon_width

                if len(file_name) > filename_width:
                    file_name = file_name[:filename_width - 3] + "..."
                file_name = file_name.ljust(filename_width)
                desc = f"{resume_icon} {file_name}"

                show_progress = task.__dict__.get('show_progress', True)
                use_tqdm = task.progress_callback is None and show_progress

                with open(task.temp_path, mode) as f:
                    if use_tqdm:
                        # ä½¿ç”¨ tqdm è¿›åº¦æ¡
                        tqdm_total = total_size if total_size > 0 else None
                        with tqdm(
                            total=tqdm_total,
                            initial=downloaded_size,
                            unit="B",
                            unit_scale=True,
                            unit_divisor=1024,
                            desc=desc,
                            position=self._get_position(),
                            bar_format='{desc:25} â”‚ {bar:25} {percentage:6.2f}% â”‚ {n_fmt:>6}/{total_fmt:<6}({rate_fmt:>5})  â”‚ {elapsed:>5} / {remaining:>5}',
                            ncols=155,
                            colour='green',
                            leave=True,  # è¿›åº¦æ¡æ˜¯å¦ä¿ç•™
                            ascii=" â–‘â–’â–“â–ˆ",
                        ) as pbar:
                            for chunk in response.iter_content(chunk_size=self.chunk_size):
                                if chunk:
                                    f.write(chunk)
                                    pbar.update(len(chunk))
                                    meta.downloaded_size += len(chunk)
                    else:
                        # ä½¿ç”¨è‡ªå®šä¹‰å›è°ƒæˆ–æ— è¿›åº¦æ˜¾ç¤º
                        start_time = time.time()
                        last_update = start_time

                        for chunk in response.iter_content(chunk_size=self.chunk_size):
                            if chunk:
                                f.write(chunk)
                                meta.downloaded_size += len(chunk)

                                # æ›´æ–°è¿›åº¦
                                if task.progress_callback:
                                    current_time = time.time()
                                    if (current_time - last_update) >= 0.5:
                                        elapsed = current_time - start_time
                                        speed = meta.downloaded_size / elapsed / \
                                            (1024 * 1024) if elapsed > 0 else 0
                                        task.progress_callback(
                                            meta.downloaded_size, meta.total_size, speed)
                                        last_update = current_time

                        # æœ€ç»ˆè¿›åº¦å›è°ƒ
                        if task.progress_callback:
                            elapsed = time.time() - start_time
                            speed = meta.total_size / elapsed / \
                                (1024 * 1024) if elapsed > 0 else 0
                            task.progress_callback(
                                meta.total_size, meta.total_size, speed)

                    # ç¡®ä¿æ•°æ®å®Œå…¨å†™å…¥ç£ç›˜
                    f.flush()
                    os.fsync(f.fileno())

                # å®‰å…¨é‡å‘½åæ–‡ä»¶
                temp_path = pathlib.Path(task.temp_path)
                full_path = pathlib.Path(task.full_path)

                if self._safe_rename_file(temp_path, full_path):
                    logger.info(f"ä¸‹è½½å®Œæˆ: {task.full_path}")
                    # æ¸…ç†å…ƒæ•°æ®
                    meta.cleanup()
                    return True

                # é‡å‘½åå¤±è´¥ï¼Œæ£€æŸ¥æœ€ç»ˆæ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼ˆå¯èƒ½æ˜¯ç«æ€æ¡ä»¶ï¼‰
                if full_path.exists() and full_path.stat().st_size > 0:
                    logger.info(f"ä¸‹è½½å®Œæˆï¼ˆæ–‡ä»¶å·²å­˜åœ¨ï¼‰: {task.full_path}")
                    meta.cleanup()
                    return True

                logger.error(f"æ–‡ä»¶é‡å‘½åå¤±è´¥: {task.temp_path} -> {task.full_path}")
                return False

            except Exception as e:
                logger.error(f"ä¸‹è½½å¼‚å¸¸ (å°è¯• {attempt + 1}/{max_retries}): {e}")

                if attempt < max_retries - 1:
                    # è¿˜æœ‰é‡è¯•æœºä¼šï¼Œä¿å­˜å…ƒæ•°æ®
                    if task.resume:
                        meta.save()
                    time.sleep(2 ** attempt)
                    continue
                else:
                    # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
                    if supports_resume is False:
                        logger.info("ä¸æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œåˆ é™¤ä¸´æ—¶æ–‡ä»¶")
                        if os.path.exists(task.temp_path):
                            try:
                                os.remove(task.temp_path)
                            except OSError:
                                pass
                    else:
                        logger.info("ä¿ç•™ä¸´æ—¶æ–‡ä»¶ä¾›ä¸‹æ¬¡ç»­ä¼ ")
                        if task.resume:
                            meta.save()
                    return False

        return False

    def batch_download(
        self,
        tasks: List[Union[DownloadTask, dict]],
        max_workers: int = 3,
        stop_on_error: bool = False
    ) -> Dict[str, bool]:
        """
        æ‰¹é‡ä¸‹è½½

        :param tasks: ä¸‹è½½ä»»åŠ¡åˆ—è¡¨
        :param max_workers: æœ€å¤§å¹¶å‘ä¸‹è½½æ•°
        :param stop_on_error: é‡åˆ°é”™è¯¯æ˜¯å¦åœæ­¢
        :return: æ¯ä¸ªä»»åŠ¡çš„ä¸‹è½½ç»“æœ
        """
        results = {}

        # è½¬æ¢å­—å…¸ä¸º DownloadTask
        task_list = []
        for task in tasks:
            if isinstance(task, dict):
                task = DownloadTask(**task)
            task_list.append(task)

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_task = {
                executor.submit(self.download_task, task): task
                for task in task_list
            }

            for future in as_completed(future_to_task):
                task = future_to_task[future]
                task_key = f"{task.request.real_url} -> {task.full_path}"

                try:
                    success = future.result()
                    results[task_key] = success

                    if not success and stop_on_error:
                        logger.error("é‡åˆ°é”™è¯¯ï¼Œåœæ­¢æ‰¹é‡ä¸‹è½½")
                        executor.shutdown(wait=False)
                        break

                except Exception as e:
                    logger.error(f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {e}")
                    results[task_key] = False

                    if stop_on_error:
                        executor.shutdown(wait=False)
                        break

        return results

    def download_from_csv(
        self,
        csv_file: str,
        save_path: str,
        url_column: str = "url",
        filename_column: Optional[str] = None,
        media_id_column: Optional[str] = None,
        max_workers: int = 3,
        max_tasks: Optional[int] = None,
        skip_existing: bool = True,
        resume: bool = True,
        show_progress: bool = True,
        stop_on_error: bool = False,
        filter_row: Optional[Callable[[Dict[str, Any], int], bool]] = None,
    ) -> Dict[str, Any]:
        """
        ä» CSV æ–‡ä»¶æ‰¹é‡ä¸‹è½½

        :param csv_file: CSV æ–‡ä»¶è·¯å¾„
        :param save_path: ä¿å­˜ç›®å½•
        :param url_column: URL åˆ—å
        :param filename_column: æ–‡ä»¶ååˆ—åï¼ˆå¯é€‰ï¼‰
        :param media_id_column: åª’ä½“ ID åˆ—åï¼ˆå¯é€‰ï¼‰
        :param max_workers: æœ€å¤§å¹¶å‘æ•°
        :param max_tasks: æœ€å¤§ä»»åŠ¡æ•°ï¼ˆNone è¡¨ç¤ºä¸é™åˆ¶ï¼‰
        :param skip_existing: æ˜¯å¦è·³è¿‡å·²å­˜åœ¨çš„æ–‡ä»¶
        :param resume: æ˜¯å¦æ”¯æŒæ–­ç‚¹ç»­ä¼ 
        :param show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡
        :param stop_on_error: é‡åˆ°é”™è¯¯æ˜¯å¦åœæ­¢
        :param filter_row: è¡Œè¿‡æ»¤å›è°ƒ (row, row_number) -> boolï¼Œè¿”å› True è¡¨ç¤ºå¤„ç†è¯¥è¡Œ
        :return: ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        csv_path = pathlib.Path(csv_file)
        if not csv_path.exists():
            logger.error(f"CSV æ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
            return {"error": "CSV file not found"}

        logger.info(f"å¼€å§‹ä» CSV å¯¼å…¥ä¸‹è½½ä»»åŠ¡: {csv_file}")
        logger.info(f"ä¿å­˜ç›®å½•: {save_path}")
        logger.info(f"å¹¶å‘æ•°: {max_workers}")

        processed_count = 0
        success_count = 0
        failed_count = 0
        skipped_count = 0

        # åˆ›å»ºä¿å­˜ç›®å½•
        pathlib.Path(save_path).mkdir(parents=True, exist_ok=True)

        def _process_row(row: Dict[str, Any], row_number: int) -> Optional[bool]:
            """å¤„ç†å•è¡Œæ•°æ®ï¼Œè¿”å› None è¡¨ç¤ºè·³è¿‡ï¼ŒTrue/False è¡¨ç¤ºæˆåŠŸ/å¤±è´¥"""
            nonlocal processed_count, success_count, failed_count, skipped_count

            try:
                # åº”ç”¨è¡Œé¢„å¤„ç†
                if self.prepare_row:
                    try:
                        row = self.prepare_row(row)
                    except Exception as e:
                        logger.warning(f"ç¬¬ {row_number} è¡Œ prepare_row å¤±è´¥: {e}")
                        return False

                # åº”ç”¨è¡Œè¿‡æ»¤
                if filter_row:
                    try:
                        if not filter_row(row, row_number):
                            logger.debug(f"ç¬¬ {row_number} è¡Œè¢«è¿‡æ»¤")
                            return None
                    except Exception as e:
                        logger.warning(f"ç¬¬ {row_number} è¡Œ filter_row å¤±è´¥: {e}")
                        return False

                # æå–å¿…è¦ä¿¡æ¯
                url = row.get(url_column)
                if not url:
                    logger.warning(f"ç¬¬ {row_number} è¡Œç¼ºå°‘ URL åˆ—: {url_column}")
                    return None

                filename = row.get(
                    filename_column) if filename_column else None
                media_id = row.get(
                    media_id_column) if media_id_column else str(row_number)

                # åˆ›å»ºè¯·æ±‚å¯¹è±¡
                request = Request(url=url)

                # ä¸‹è½½æ–‡ä»¶
                result = self.download(
                    request=request,
                    save_path=save_path,
                    filename=filename,
                    resume=resume,
                    skip_existing=skip_existing,
                    show_progress=show_progress,
                    media_id=media_id,
                    row_data=row,
                )

                return result

            except Exception as e:
                logger.error(f"ç¬¬ {row_number} è¡Œå¤„ç†å¼‚å¸¸: {e}")
                return False

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = []

            try:
                with open(csv_path, 'r', encoding='utf-8') as f:
                    reader = csv.DictReader(f)

                    for row_number, row in enumerate(reader, start=1):
                        if max_tasks and processed_count >= max_tasks:
                            logger.info(f"å·²è¾¾åˆ°æœ€å¤§ä»»åŠ¡æ•°é™åˆ¶: {max_tasks}")
                            break

                        processed_count += 1

                        # æäº¤ä»»åŠ¡
                        future = executor.submit(_process_row, row, row_number)
                        futures.append(future)

                # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
                for future in as_completed(futures):
                    try:
                        result = future.result()
                        if result is None:
                            skipped_count += 1
                        elif result:
                            success_count += 1
                        else:
                            failed_count += 1
                            if stop_on_error:
                                logger.error("é‡åˆ°é”™è¯¯ï¼Œåœæ­¢æ‰¹é‡ä¸‹è½½")
                                executor.shutdown(
                                    wait=False, cancel_futures=True)
                                break
                    except Exception as e:
                        logger.error(f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {e}")
                        failed_count += 1
                        if stop_on_error:
                            executor.shutdown(wait=False, cancel_futures=True)
                            break

            except Exception as e:
                logger.error(f"è¯»å– CSV æ–‡ä»¶å¤±è´¥: {e}")
                return {"error": str(e)}

        # ç»Ÿè®¡ä¿¡æ¯
        stats = {
            "total": processed_count,
            "success": success_count,
            "failed": failed_count,
            "skipped": skipped_count,
        }

        logger.info("=" * 60)
        logger.info("ä¸‹è½½ç»Ÿè®¡ï¼š")
        logger.info(f"  æ€»è®¡: {stats['total']}")
        logger.info(f"  æˆåŠŸ: {stats['success']}")
        logger.info(f"  å¤±è´¥: {stats['failed']}")
        logger.info(f"  è·³è¿‡: {stats['skipped']}")
        logger.info("=" * 60)

        return stats
